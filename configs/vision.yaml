# configs/vision.yaml
camera:
  camera_id: 0
  resolution: [1280, 720]

  # Bloqueá autoexposición / balance para que no cambien entre demos.
  exposure_fixed: null          # ej: -6 en OpenCV; si no sabés, dejá null
  white_balance_fixed: null     # ej: 4600 (Kelvin) si tu driver lo permite

roi:
  # Región donde "cae" el objeto para clasificar (en píxeles: x, y, w, h)
  # Empezamos con algo genérico; luego lo vas a ajustar mirando la imagen.
  px: [500, 200, 320, 320]

  # Si llevás un rig con fiduciales, normalizamos la ROI aunque la cámara
  # quede un poco corrida.
  normalize_with_fiducials: true

fiducials:
  enabled: true
  # IDs de ArUco/AprilTag pegados en tu base (opcional, para validación/alineación)
  # Dejalo como lista vacía si aún no los usás.
  ids: []

presence:
  method: "bgdiff"          # bgdiff | edges
  bg_capture_on_start: true
  stable_ms: 350            # exigir ocupación estable por este tiempo

classifier:
  model_path: "models/classifier_v1.onnx"
  input_size: [224, 224]
  vote_frames: 5            # votación temporal (robustez)
  confidence_threshold: 0.85
